{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_infersent.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNUxN69zzR2mnKwpwmW74x0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boscoj2008/infersent-train-2021/blob/main/train_infersent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoFabAVrI1S-"
      },
      "source": [
        "# Training the InferSent algorithm on SNLI corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvO5WsyuXEh_"
      },
      "source": [
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://miro.medium.com/max/768/1*78sgGtCOQ8PHHnV6Wg4WNQ.png' />\n",
        "<figcaption>bi-LSTM encoder</figcaption></center>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiE9avlboAVi"
      },
      "source": [
        "## clone model repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59PBQtHq9ecY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f17a518-3197-49a1-bfb7-f55153e2611b"
      },
      "source": [
        "!git clone https://github.com/dozed/InferSent.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'InferSent'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 19 (delta 1), reused 19 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (19/19), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4mf-Iv9AMCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a1d3d58-1b51-4a22-9677-5276b9adefe8"
      },
      "source": [
        "# change directory to InferSent\n",
        "%cd InferSent"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/InferSent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI9zlcNGki3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14fff04e-dc1b-4d72-9a80-5331cb26081f"
      },
      "source": [
        "ls "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CODE_OF_CONDUCT.md  \u001b[0m\u001b[01;34mdataset\u001b[0m/    \u001b[01;32mextract_features.py\u001b[0m*  \u001b[01;32mmutils.py\u001b[0m*\n",
            "CONTRIBUTING.md     demo.ipynb  LICENSE               \u001b[01;32mREADME.md\u001b[0m*\n",
            "\u001b[01;32mdata.py\u001b[0m*            \u001b[01;34mencoder\u001b[0m/    \u001b[01;32mmodels.py\u001b[0m*            \u001b[01;32mtrain_nli.py\u001b[0m*\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILoRFW4hggzr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1627123-4e70-4d09-e322-816714bd82d9"
      },
      "source": [
        "ls dataset/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;32mget_data.bash\u001b[0m*  \u001b[01;32mtokenizer.sed\u001b[0m*\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zWz1qJVgkKz"
      },
      "source": [
        "# download training data (SNLI or Multi-SNLI)\n",
        "# !./dataset/get_data.bash"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KofL93rfHpGU"
      },
      "source": [
        "## Download data from stanford wedsite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hyw0lAEUHyoY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e45fb47-d6e9-47eb-8c22-437a8e9f7891"
      },
      "source": [
        "!wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-14 04:23:33--  https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94550081 (90M) [application/zip]\n",
            "Saving to: ‘snli_1.0.zip’\n",
            "\n",
            "snli_1.0.zip        100%[===================>]  90.17M  2.35MB/s    in 13s     \n",
            "\n",
            "2021-09-14 04:23:47 (6.92 MB/s) - ‘snli_1.0.zip’ saved [94550081/94550081]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UB49xHvUimn",
        "outputId": "59781ee5-f8f3-451c-a8ae-14507973e3d5"
      },
      "source": [
        "!unzip snli_1.0.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  snli_1.0.zip\n",
            "   creating: snli_1.0/\n",
            "  inflating: snli_1.0/.DS_Store      \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/snli_1.0/\n",
            "  inflating: __MACOSX/snli_1.0/._.DS_Store  \n",
            " extracting: snli_1.0/Icon           \n",
            "  inflating: __MACOSX/snli_1.0/._Icon  \n",
            "  inflating: snli_1.0/README.txt     \n",
            "  inflating: __MACOSX/snli_1.0/._README.txt  \n",
            "  inflating: snli_1.0/snli_1.0_dev.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_dev.txt  \n",
            "  inflating: snli_1.0/snli_1.0_test.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_test.txt  \n",
            "  inflating: snli_1.0/snli_1.0_train.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_train.txt  \n",
            "  inflating: __MACOSX/._snli_1.0     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6feoAPlWIRRc"
      },
      "source": [
        "!mv snli_1.0/ dataset/"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z8hPPiYobL-"
      },
      "source": [
        "## Download glove model from [here](https://nlp.stanford.edu/projects/glove/) or follow steps below;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FQLfpzSh1o7"
      },
      "source": [
        "# make a folder for glove model\n",
        "!mkdir dataset/GloVe"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YEXtE94iffs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecfe8b00-af03-41fa-84ce-f7f6d9e71a7c"
      },
      "source": [
        "# using file link and wget, \n",
        "# download the model to colab\n",
        "!wget https://nlp.stanford.edu/data/glove.840B.300d.zip"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-14 04:24:52--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",
            "--2021-09-14 04:24:52--  http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘glove.840B.300d.zip’\n",
            "\n",
            "glove.840B.300d.zip 100%[===================>]   2.03G  5.15MB/s    in 6m 53s  \n",
            "\n",
            "2021-09-14 04:31:46 (5.03 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCCGg58jAL7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0f9ddb5-c4a2-4573-dec5-9a543463f46b"
      },
      "source": [
        "# unpack model from zip\n",
        "!unzip glove.840B.300d.zip"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.840B.300d.zip\n",
            "  inflating: glove.840B.300d.txt     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrP0yzp3fwpl"
      },
      "source": [
        "!mv glove.840B.300d.txt dataset/GloVe/"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqtyfyeHUxK4"
      },
      "source": [
        "### import nltk , nlp language proccessor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLSAlpukIFm1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5392b37-59c4-43d3-8114-52969a08b8f5"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKTI-oHoU2mF"
      },
      "source": [
        "## Train inferSent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1QMb9M3U7p6"
      },
      "source": [
        "- make changes to the data.py script at line 120 from csv to txt, add sep=\"\\t\"\n",
        "- make sure to change the GPU id too as below\n",
        "- everything else stays the same"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XdLDIZOUVvp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d5efac4-8d23-40a3-af30-4dba3916a563"
      },
      "source": [
        "!python3 train_nli.py \\\n",
        "  --epochs 2 \\\n",
        "  --batch_size 64 \\\n",
        "  --corpus mnli \\\n",
        "  --encoder_type InferSent \\\n",
        "  --activation tanh \\\n",
        "  --embed_dim 300 \\\n",
        "  --fc_dim 512 \\\n",
        "  --hidden_dim 2048 \\\n",
        "  --layers 1 \\\n",
        "  --save_path results \\\n",
        "  --seed 1234 \\\n",
        "  --gpu_id 0 \\\n",
        "  --nlipath \"dataset/snli_1.0\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "togrep : ['--epochs', '2', '--batch_size', '64', '--corpus', 'mnli', '--encoder_type', 'InferSent', '--activation', 'tanh', '--embed_dim', '300', '--fc_dim', '512', '--hidden_dim', '2048', '--layers', '1', '--save_path', 'results', '--seed', '1234', '--gpu_id', '0', '--nlipath', 'dataset/snli_1.0']\n",
            "\n",
            "Namespace(batch_size=64, decay=0.99, dpout_fc=0.0, dpout_model=0.0, enc_lstm_dim=2048, encoder_type='InferSent', fc_dim=512, gpu_id=0, lrshrink=5, max_norm=5.0, minlr=1e-05, n_classes=3, n_enc_layers=1, n_epochs=20, nlipath='dataset/snli_1.0', nonlinear_fc=0, optimizer='sgd,lr=0.1', outputdir='savedir/', outputmodelname='model.pickle', pool_type='max', seed=1234, word_emb_dim=300, word_emb_path='dataset/GloVe/glove.840B.300d.txt')\n",
            "** TRAIN DATA : Found 549367 pairs of train sentences.\n",
            "** DEV DATA : Found 9842 pairs of dev sentences.\n",
            "** TEST DATA : Found 9824 pairs of test sentences.\n",
            "Found 32789(/37251) words with glove vectors\n",
            "Vocab size : 32789\n",
            "train_nli.py:87: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  ['</s>'] for sent in eval(data_type)[split]])\n",
            "NLINet(\n",
            "  (encoder): InferSent(\n",
            "    (enc_lstm): LSTM(300, 2048, bidirectional=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=16384, out_features=512, bias=True)\n",
            "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (2): Linear(in_features=512, out_features=3, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "TRAINING : Epoch 1\n",
            "Learning rate : 0.1\n",
            "6336 ; loss 1.1 ; sentence/s 131 ; words/s 7561 ; accuracy train : 33.28\n",
            "12736 ; loss 1.1 ; sentence/s 130 ; words/s 7464 ; accuracy train : 33.37\n",
            "19136 ; loss 1.1 ; sentence/s 128 ; words/s 7564 ; accuracy train : 33.56\n",
            "25536 ; loss 1.1 ; sentence/s 129 ; words/s 7484 ; accuracy train : 33.48\n",
            "31936 ; loss 1.1 ; sentence/s 128 ; words/s 7442 ; accuracy train : 33.69\n",
            "38336 ; loss 1.1 ; sentence/s 128 ; words/s 7538 ; accuracy train : 33.59\n",
            "44736 ; loss 1.1 ; sentence/s 128 ; words/s 7461 ; accuracy train : 33.69\n",
            "51136 ; loss 1.1 ; sentence/s 128 ; words/s 7555 ; accuracy train : 33.75\n",
            "57536 ; loss 1.1 ; sentence/s 129 ; words/s 7401 ; accuracy train : 33.78\n",
            "63936 ; loss 1.1 ; sentence/s 128 ; words/s 7437 ; accuracy train : 33.71\n",
            "70336 ; loss 1.1 ; sentence/s 129 ; words/s 7412 ; accuracy train : 33.69\n",
            "76736 ; loss 1.1 ; sentence/s 129 ; words/s 7274 ; accuracy train : 33.73\n",
            "83136 ; loss 1.1 ; sentence/s 129 ; words/s 7329 ; accuracy train : 33.7\n",
            "89536 ; loss 1.1 ; sentence/s 128 ; words/s 7582 ; accuracy train : 33.87\n",
            "95936 ; loss 1.1 ; sentence/s 128 ; words/s 7524 ; accuracy train : 33.95\n",
            "102336 ; loss 1.1 ; sentence/s 127 ; words/s 7652 ; accuracy train : 33.96\n",
            "108736 ; loss 1.1 ; sentence/s 128 ; words/s 7452 ; accuracy train : 33.94\n",
            "115136 ; loss 1.1 ; sentence/s 128 ; words/s 7494 ; accuracy train : 33.93\n",
            "121536 ; loss 1.1 ; sentence/s 127 ; words/s 7575 ; accuracy train : 33.87\n",
            "127936 ; loss 1.1 ; sentence/s 129 ; words/s 7406 ; accuracy train : 33.97\n",
            "134336 ; loss 1.1 ; sentence/s 129 ; words/s 7539 ; accuracy train : 34.22\n",
            "140736 ; loss 1.1 ; sentence/s 129 ; words/s 7468 ; accuracy train : 34.33\n",
            "147136 ; loss 1.1 ; sentence/s 128 ; words/s 7428 ; accuracy train : 34.48\n",
            "153536 ; loss 1.1 ; sentence/s 129 ; words/s 7310 ; accuracy train : 34.65\n",
            "159936 ; loss 1.1 ; sentence/s 128 ; words/s 7461 ; accuracy train : 34.79\n",
            "166336 ; loss 1.1 ; sentence/s 128 ; words/s 7368 ; accuracy train : 34.93\n",
            "172736 ; loss 1.1 ; sentence/s 127 ; words/s 7429 ; accuracy train : 35.06\n",
            "179136 ; loss 1.1 ; sentence/s 130 ; words/s 7394 ; accuracy train : 35.2\n",
            "185536 ; loss 1.1 ; sentence/s 128 ; words/s 7425 ; accuracy train : 35.35\n",
            "191936 ; loss 1.1 ; sentence/s 128 ; words/s 7487 ; accuracy train : 35.43\n",
            "198336 ; loss 1.1 ; sentence/s 128 ; words/s 7540 ; accuracy train : 35.49\n",
            "204736 ; loss 1.1 ; sentence/s 128 ; words/s 7511 ; accuracy train : 35.68\n",
            "211136 ; loss 1.1 ; sentence/s 128 ; words/s 7383 ; accuracy train : 35.96\n",
            "217536 ; loss 1.1 ; sentence/s 127 ; words/s 7507 ; accuracy train : 36.23\n",
            "223936 ; loss 1.1 ; sentence/s 128 ; words/s 7524 ; accuracy train : 36.42\n",
            "230336 ; loss 1.1 ; sentence/s 127 ; words/s 7545 ; accuracy train : 36.65\n",
            "236736 ; loss 1.1 ; sentence/s 129 ; words/s 7572 ; accuracy train : 36.96\n",
            "243136 ; loss 1.1 ; sentence/s 130 ; words/s 7430 ; accuracy train : 37.24\n",
            "249536 ; loss 1.1 ; sentence/s 129 ; words/s 7513 ; accuracy train : 37.32\n",
            "255936 ; loss 1.1 ; sentence/s 130 ; words/s 7429 ; accuracy train : 37.4\n",
            "262336 ; loss 1.1 ; sentence/s 129 ; words/s 7548 ; accuracy train : 37.52\n",
            "268736 ; loss 1.1 ; sentence/s 128 ; words/s 7587 ; accuracy train : 37.72\n",
            "275136 ; loss 1.1 ; sentence/s 128 ; words/s 7805 ; accuracy train : 37.91\n",
            "281536 ; loss 1.1 ; sentence/s 129 ; words/s 7534 ; accuracy train : 38.02\n",
            "287936 ; loss 1.1 ; sentence/s 128 ; words/s 7577 ; accuracy train : 38.13\n",
            "294336 ; loss 1.1 ; sentence/s 128 ; words/s 7576 ; accuracy train : 38.17\n",
            "300736 ; loss 1.1 ; sentence/s 129 ; words/s 7459 ; accuracy train : 38.16\n",
            "307136 ; loss 1.1 ; sentence/s 128 ; words/s 7580 ; accuracy train : 38.1\n",
            "313536 ; loss 1.1 ; sentence/s 128 ; words/s 7564 ; accuracy train : 38.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z1J5Dkn_ZkE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}